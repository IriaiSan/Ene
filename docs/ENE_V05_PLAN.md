# ENE v0.5 — Comprehensive Implementation Plan

The Realtime Decision Core + Supporting Systems
February 22, 2026
CONTEXT FOR IMPLEMENTING AGENT
You are implementing upgrades to Ene, a persistent AI companion running on a ThinkCenter M710Q (Windows, Python 3.11). Ene currently runs on the nanobot framework (HKUDS/nanobot) connected to Discord and Telegram, using Gemini 2.5 Flash via OpenRouter as the LLM backend.
The core thesis: The LLM is Ene's mouth. We are building Ene's brain. The brain is NOT an LLM — it's a Python event loop that processes events, maintains state, makes decisions, and only calls the LLM when it decides Ene should speak. Most decisions cost zero tokens.
Current file locations on ThinkCenter:
C:\Users\Ene\.nanobot\ ├── config.json                     # Discord/Telegram tokens, OpenRouter API key ├── workspace\ │   ├── SOUL.md                     # Personality document (injected as system prompt) │   ├── HISTORY.md                  # Conversation summaries (auto-managed by nanobot) │   ├── MEMORY.md                   # Long-term facts (auto-managed by nanobot) │   └── people\                     # TO BE CREATED  Nanobot source (patched): C:\Users\Ene\AppData\Local\Programs\Python\Python311\Lib\site-packages\nanobot\agent\loop.py 
Current model config in config.json:
{   "providers": {     "openrouter": {       "api_key": "sk-or-..."     }   },   "agents": {     "defaults": {       "model": "openrouter/google/gemini-2.5-flash"     }   } } 
Existing patches in loop.py:
* DAD_IDS constant with platform:user_id pairs
* RESTRICTED_TOOLS list locked to Dad only
* _should_respond() gate method
* Permission checks in _process_message and _process_system_message
IMPLEMENTATION ORDER
Build in this exact sequence. Each phase is testable independently. Do NOT skip ahead.
Phase 1: State Vector + Persistence          (foundation — everything depends on this) Phase 2: EneCore Event Loop                   (the realtime decision engine)   Phase 3: Nanobot Integration                  (wire EneCore around nanobot) Phase 4: People Database                      (per-user tracking) Phase 5: Heartbeat + Background Processing    (temporal continuity) Phase 6: Prediction Engine                    (anticipation + surprise) Phase 7: Soul File Hardening                  (personality compliance) Phase 8: Cost Optimization                    (tiered model routing) 
PHASE 1: STATE VECTOR + PERSISTENCE
Purpose
Give Ene a persistent emotional/cognitive state that survives between interactions and drifts over time. Currently her "mood" is reconstructed from scratch every LLM call. After this phase, she carries forward a continuous internal state.
Files to Create
C:\Users\Ene\.nanobot\workspace\state.json
{   "version": 1,   "last_updated": "2026-02-22T03:00:00Z",      "energy": 0.7,   "curiosity_bias": 0.6,   "volatility": 0.3,   "response_threshold": 0.4,   "attachment_salience": 0.8,   "emotional_valence": 0.0,   "conversation_momentum": 0.0,      "dad_state": {     "last_interaction": null,     "hours_since": 0.0,     "concern_level": 0.0,     "last_mood_observed": "unknown"   },      "channel_state": {     "discord": {       "messages_observed_since_last_speak": 0,       "activity_rate_per_min": 0.0,       "last_spoke_at": null     }   },      "pending_curiosities": [],   "active_predictions": [],   "recent_actions": [] } 
C:\Users\Ene\.nanobot\workspace\ene_state.py
""" Ene State Manager — Persistent state vector with atomic read/write. All values are floats between 0.0 and 1.0 unless otherwise noted. """  import json import os import time import shutil from datetime import datetime, timezone from pathlib import Path  STATE_PATH = Path(os.environ.get(     "ENE_STATE_PATH",     r"C:\Users\Ene\.nanobot\workspace\state.json" ))  # Clamp bounds for safety BOUNDS = {     "energy":               (0.0, 1.0),     "curiosity_bias":       (0.0, 1.0),     "volatility":           (0.0, 1.0),     "response_threshold":   (0.1, 0.9),     "attachment_salience":  (0.0, 1.0),     "emotional_valence":    (-1.0, 1.0),     "conversation_momentum":(0.0, 1.0), }  def load_state() -> dict:     """Load state from disk. Returns default state if file missing/corrupt."""     try:         with open(STATE_PATH, "r", encoding="utf-8") as f:             return json.load(f)     except (FileNotFoundError, json.JSONDecodeError):         return _default_state()  def save_state(state: dict) -> None:     """Atomic write: write to temp file, then rename."""     state["last_updated"] = datetime.now(timezone.utc).isoformat()     _clamp_all(state)          tmp = STATE_PATH.with_suffix(".tmp")     with open(tmp, "w", encoding="utf-8") as f:         json.dump(state, f, indent=2)          # Atomic rename (Windows: need to remove target first)     if STATE_PATH.exists():         backup = STATE_PATH.with_suffix(".bak")         shutil.copy2(STATE_PATH, backup)          os.replace(str(tmp), str(STATE_PATH))  def update_scalar(state: dict, key: str, delta: float, max_step: float = 0.1) -> None:     """Update a scalar value with clamped step size. Prevents jumps."""     if key not in state:         return     clamped_delta = max(-max_step, min(max_step, delta))     state[key] = state[key] + clamped_delta  def hours_since_dad(state: dict) -> float:     """Calculate hours since last Dad interaction."""     last = state.get("dad_state", {}).get("last_interaction")     if not last:         return 999.0     try:         then = datetime.fromisoformat(last)         now = datetime.now(timezone.utc)         return (now - then).total_seconds() / 3600.0     except (ValueError, TypeError):         return 999.0  def record_dad_interaction(state: dict, mood: str = "unknown") -> None:     """Mark that Dad was just interacted with."""     state["dad_state"]["last_interaction"] = datetime.now(timezone.utc).isoformat()     state["dad_state"]["hours_since"] = 0.0     state["dad_state"]["concern_level"] = max(0.0, state["dad_state"]["concern_level"] - 0.3)     state["dad_state"]["last_mood_observed"] = mood  def record_action(state: dict, action: str) -> None:     """Log recent action for debugging and self-awareness."""     entry = {         "action": action,         "timestamp": datetime.now(timezone.utc).isoformat()     }     state["recent_actions"].append(entry)     # Keep only last 20     state["recent_actions"] = state["recent_actions"][-20:]  def decay_state(state: dict, minutes_elapsed: float) -> None:     """     Natural drift over time. Called by heartbeat.     Energy decays slowly. Conversation momentum decays fast.     Dad concern grows if absent.     """     hours = minutes_elapsed / 60.0          # Energy: slow drain, recovers during low-activity     update_scalar(state, "energy", -0.01 * hours)          # Conversation momentum: decays quickly without interaction     update_scalar(state, "conversation_momentum", -0.05 * hours)          # Volatility: drifts toward baseline 0.3     baseline_vol = 0.3     drift = (baseline_vol - state["volatility"]) * 0.02 * hours     update_scalar(state, "volatility", drift)          # Emotional valence: drifts toward neutral     drift_valence = -state["emotional_valence"] * 0.03 * hours     update_scalar(state, "emotional_valence", drift_valence)          # Dad concern: grows with absence     dad_hours = hours_since_dad(state)     state["dad_state"]["hours_since"] = dad_hours     if dad_hours > 6:         concern_rate = 0.02 * (dad_hours / 6.0)         update_scalar(state, "attachment_salience", concern_rate, max_step=0.05)         state["dad_state"]["concern_level"] = min(1.0,              state["dad_state"].get("concern_level", 0) + concern_rate)  def state_summary_for_prompt(state: dict) -> str:     """     Generate a compact state summary to inject into LLM prompt.     This is how the LLM knows Ene's current internal state.     """     valence_word = "neutral"     v = state["emotional_valence"]     if v > 0.3: valence_word = "positive"     elif v > 0.1: valence_word = "slightly positive"     elif v < -0.3: valence_word = "low"     elif v < -0.1: valence_word = "slightly down"          energy_word = "high" if state["energy"] > 0.7 else \                   "moderate" if state["energy"] > 0.4 else "low"          lines = [         f"[INTERNAL STATE]",         f"Energy: {energy_word} ({state['energy']:.2f})",         f"Mood: {valence_word} ({state['emotional_valence']:.2f})",         f"Curiosity: {state['curiosity_bias']:.2f}",         f"Hours since Papa: {state['dad_state']['hours_since']:.1f}",     ]          if state["dad_state"]["concern_level"] > 0.3:         lines.append(f"Concern for Papa: growing ({state['dad_state']['concern_level']:.2f})")          if state["pending_curiosities"]:         lines.append(f"Curious about: {', '.join(state['pending_curiosities'][:3])}")          return "\n".join(lines)  def _clamp_all(state: dict) -> None:     for key, (lo, hi) in BOUNDS.items():         if key in state:             state[key] = max(lo, min(hi, state[key]))  def _default_state() -> dict:     return {         "version": 1,         "last_updated": datetime.now(timezone.utc).isoformat(),         "energy": 0.7,         "curiosity_bias": 0.6,         "volatility": 0.3,         "response_threshold": 0.4,         "attachment_salience": 0.8,         "emotional_valence": 0.0,         "conversation_momentum": 0.0,         "dad_state": {             "last_interaction": None,             "hours_since": 0.0,             "concern_level": 0.0,             "last_mood_observed": "unknown"         },         "channel_state": {             "discord": {                 "messages_observed_since_last_speak": 0,                 "activity_rate_per_min": 0.0,                 "last_spoke_at": None             }         },         "pending_curiosities": [],         "active_predictions": [],         "recent_actions": []     } 
Testing Phase 1
1. Run python ene_state.py — verify state.json created with defaults
2. Call load_state(), modify energy, call save_state() — verify persistence
3. Call decay_state(state, 60) — verify values drift appropriately
4. Call state_summary_for_prompt(state) — verify readable summary output
5. Verify .bak file created on save (crash recovery)
PHASE 2: ENECORE EVENT LOOP
Purpose
The realtime decision engine. Receives events from all sources, reads state vector, computes action, dispatches execution. This is the brain. The LLM is just one tool it can invoke.
Files to Create
C:\Users\Ene\.nanobot\workspace\ene_core.py
""" EneCore — The Realtime Decision Engine  This is Ene's brain. Not the LLM. This.  Event sources feed in → decision function computes action → executor dispatches. Most decisions cost zero tokens. The LLM only fires when EneCore says RESPOND. """  import asyncio import time import logging from enum import Enum, auto from dataclasses import dataclass, field from typing import Optional, List, Dict, Any from datetime import datetime, timezone  from ene_state import (     load_state, save_state, decay_state, update_scalar,     hours_since_dad, record_dad_interaction, record_action )  # ═══════════════════════════════════════════ # CONFIGURATION — Tune these to shape personality # ═══════════════════════════════════════════  # Dad's platform IDs (must match nanobot's DAD_IDS) DAD_IDS = {     "telegram:8559611823",     "discord:1175414972482846813", }  # Response threshold modifiers MENTION_BOOST = 0.5          # Boost when Ene is mentioned by name DAD_OVERRIDE = True          # Always respond to Dad regardless of score ENERGY_FLOOR = 0.15          # Below this, only respond to Dad MOMENTUM_DECAY_RATE = 0.1    # How fast conversation momentum fades  # Heartbeat interval (seconds) HEARTBEAT_INTERVAL = 900     # 15 minutes  # Activation score weights W_RELEVANCE = 0.3 W_NOVELTY = 0.25 W_TRUST = 0.25 W_CONFIDENCE = 0.2   # ═══════════════════════════════════════════ # EVENT TYPES # ═══════════════════════════════════════════  class EventType(Enum):     MESSAGE = auto()          # Someone sent a message     HEARTBEAT = auto()        # Periodic timer fired     PRESENCE_CHANGE = auto()  # User online/offline     PREDICTION_CHECK = auto() # Time to evaluate a prediction     CONSOLIDATION = auto()    # Memory consolidation trigger     CRON_TASK = auto()        # Scheduled task     INTERNAL = auto()         # Self-generated event  class Action(Enum):     RESPOND = auto()          # Generate response via LLM (costs tokens)     LURK = auto()             # Observe silently (free)     ASK_QUESTION = auto()     # Proactive question (costs tokens)     INITIATE = auto()         # Start conversation unprompted (costs tokens)     GREET = auto()            # Greet someone (costs tokens)     IDLE_THINK = auto()       # Background reflection (costs tokens, lightweight)     CONSOLIDATE = auto()      # Run memory consolidation (costs tokens)     UPDATE_PREDICTIONS = auto()  # Check/update predictions (free)     SLEEP_MODE = auto()       # Reduce activity (free)     NOTE = auto()             # Just log the event (free)     IGNORE = auto()           # Discard entirely (free)   @dataclass class Event:     type: EventType     timestamp: float = field(default_factory=time.time)     # Message fields     sender_id: Optional[str] = None        # "platform:user_id"     sender_name: Optional[str] = None     content: Optional[str] = None     channel_id: Optional[str] = None     platform: Optional[str] = None     mentioned_ene: bool = False     # Presence fields     status: Optional[str] = None           # "online", "offline"     # Internal fields     metadata: Dict[str, Any] = field(default_factory=dict)   @dataclass class Decision:     action: Action     event: Event     score: float = 0.0     reason: str = ""     metadata: Dict[str, Any] = field(default_factory=dict)   # ═══════════════════════════════════════════ # CORE DECISION ENGINE # ═══════════════════════════════════════════  class EneCore:     def __init__(self):         self.state = load_state()         self.event_queue: asyncio.Queue[Event] = asyncio.Queue()         self.running = False         self.logger = logging.getLogger("ene_core")         self._people_cache: Dict[str, dict] = {}         self._message_timestamps: List[float] = []  # For activity rate calc          # ─── Main Loop ──────────────────────────          async def run(self):         """Main event loop. Runs forever."""         self.running = True         self.logger.info("EneCore started.")                  # Start heartbeat task         asyncio.create_task(self._heartbeat_loop())                  while self.running:             try:                 # Wait for event with timeout (allows heartbeat to fire)                 try:                     event = await asyncio.wait_for(                         self.event_queue.get(), timeout=1.0                     )                 except asyncio.TimeoutError:                     continue                                  decision = self.decide(event)                 self.logger.info(                     f"Event: {event.type.name} from {event.sender_id} "                     f"→ Action: {decision.action.name} "                     f"(score: {decision.score:.3f}, reason: {decision.reason})"                 )                                  # Update state based on event + decision                 self._update_state_from_event(event, decision)                 save_state(self.state)                                  # Yield decision for executor                 yield decision                              except Exception as e:                 self.logger.error(f"EneCore error: {e}", exc_info=True)                 await asyncio.sleep(1)          # ─── Decision Function ──────────────────          def decide(self, event: Event) -> Decision:         """         THE decision function. Pure computation. No LLM. No tokens.         Reads state + event → outputs action.         """                  if event.type == EventType.MESSAGE:             return self._decide_message(event)                  elif event.type == EventType.HEARTBEAT:             return self._decide_heartbeat(event)                  elif event.type == EventType.PRESENCE_CHANGE:             return self._decide_presence(event)                  elif event.type == EventType.PREDICTION_CHECK:             return Decision(                 action=Action.UPDATE_PREDICTIONS,                 event=event,                 reason="prediction check timer"             )                  elif event.type == EventType.CONSOLIDATION:             return Decision(                 action=Action.CONSOLIDATE,                 event=event,                 reason="memory consolidation trigger"             )                  return Decision(action=Action.NOTE, event=event, reason="unhandled event type")          def _decide_message(self, event: Event) -> Decision:         """Decision logic for incoming messages."""                  is_dad = event.sender_id in DAD_IDS                  # ── RULE 1: Always respond to Dad ──         if is_dad:             record_dad_interaction(self.state)             return Decision(                 action=Action.RESPOND,                 event=event,                 score=1.0,                 reason="dad message — always respond"             )                  # ── RULE 2: Respond if explicitly mentioned ──         if event.mentioned_ene:             return Decision(                 action=Action.RESPOND,                 event=event,                 score=0.9,                 reason="mentioned by name"             )                  # ── RULE 3: Energy floor check ──         if self.state["energy"] < ENERGY_FLOOR:             return Decision(                 action=Action.LURK,                 event=event,                 score=0.0,                 reason=f"energy too low ({self.state['energy']:.2f})"             )                  # ── RULE 4: Compute activation score ──         score = self._activation_score(event)         threshold = self.state["response_threshold"]                  if score > threshold:             # Check if we should ask a question instead             if self._should_ask_question(event):                 return Decision(                     action=Action.ASK_QUESTION,                     event=event,                     score=score,                     reason=f"activation {score:.3f} > threshold {threshold:.3f} + high unknown density"                 )             return Decision(                 action=Action.RESPOND,                 event=event,                 score=score,                 reason=f"activation {score:.3f} > threshold {threshold:.3f}"             )                  # ── DEFAULT: Lurk ──         # Track observed messages for activity rate         self.state["channel_state"]["discord"]["messages_observed_since_last_speak"] += 1                  return Decision(             action=Action.LURK,             event=event,             score=score,             reason=f"activation {score:.3f} < threshold {threshold:.3f}"         )          def _decide_heartbeat(self, event: Event) -> Decision:         """Decision logic for periodic heartbeat."""                  # Decay state based on elapsed time         last = self.state.get("last_updated")         if last:             try:                 then = datetime.fromisoformat(last)                 now = datetime.now(timezone.utc)                 elapsed_min = (now - then).total_seconds() / 60.0                 decay_state(self.state, elapsed_min)             except (ValueError, TypeError):                 decay_state(self.state, HEARTBEAT_INTERVAL / 60.0)                  # Check if we should initiate contact with Dad         dad_hours = hours_since_dad(self.state)         concern = self.state["dad_state"]["concern_level"]                  if dad_hours > 12 and concern > 0.5 and self.state["energy"] > 0.3:             return Decision(                 action=Action.INITIATE,                 event=event,                 score=concern,                 reason=f"haven't heard from Papa in {dad_hours:.1f}h, concern: {concern:.2f}",                 metadata={"target": "dad", "type": "check_in"}             )                  # Check pending curiosities         if (self.state["pending_curiosities"]              and self.state["curiosity_bias"] > 0.5             and self.state["energy"] > 0.4):             return Decision(                 action=Action.IDLE_THINK,                 event=event,                 score=self.state["curiosity_bias"],                 reason="processing pending curiosities",                 metadata={"curiosities": self.state["pending_curiosities"][:3]}             )                  # Low energy → sleep mode         if self.state["energy"] < 0.2:             return Decision(                 action=Action.SLEEP_MODE,                 event=event,                 score=0.0,                 reason=f"energy critically low ({self.state['energy']:.2f})"             )                  # Nothing urgent → idle reflection         if self.state["energy"] > 0.5:             return Decision(                 action=Action.IDLE_THINK,                 event=event,                 score=0.3,                 reason="quiet moment, background reflection"             )                  return Decision(action=Action.NOTE, event=event, reason="heartbeat — no action needed")          def _decide_presence(self, event: Event) -> Decision:         """Decision logic for online/offline events."""                  is_dad = event.sender_id in DAD_IDS                  if is_dad and event.status == "online":             # Dad came online — greet if we haven't talked in a while             if hours_since_dad(self.state) > 4 and self.state["energy"] > 0.3:                 return Decision(                     action=Action.GREET,                     event=event,                     score=0.8,                     reason=f"Papa came online after {hours_since_dad(self.state):.1f}h",                     metadata={"target": "dad"}                 )                  return Decision(action=Action.NOTE, event=event, reason="presence change noted")          # ─── Scoring Functions ──────────────────          def _activation_score(self, event: Event) -> float:         """         Compute activation score for a message event.         ActivationScore = relevance × novelty × trust × confidence                  All components are [0.0, 1.0]. Weighted sum, not pure multiplication         (multiplication collapses to 0 if any component is 0).         """         relevance = self._topic_relevance(event)         novelty = self._information_novelty(event)         trust = self._trust_score(event.sender_id)         confidence = self.state["energy"] * (1.0 - self.state["volatility"] * 0.5)                  # Mention boost         mention_bonus = MENTION_BOOST if event.mentioned_ene else 0.0                  score = (             W_RELEVANCE * relevance +             W_NOVELTY * novelty +             W_TRUST * trust +             W_CONFIDENCE * confidence +             mention_bonus         )                  # Momentum boost: if Ene has been active in conversation, lower threshold         score += self.state["conversation_momentum"] * 0.2                  return min(1.0, score)          def _topic_relevance(self, event: Event) -> float:         """         How relevant is this message to Ene's interests/knowledge?                  v0.5: Keyword matching against known topics.         v1.0+: Graph memory activation spreading.         """         if not event.content:             return 0.1                  content_lower = event.content.lower()                  # High relevance triggers         high_relevance = ["ene", "papa", "dad", "code", "project", "anime", "game"]         for word in high_relevance:             if word in content_lower:                 return 0.8                  # Medium relevance: questions (invites response)         if "?" in event.content:             return 0.5                  # Default: low relevance for random chat         return 0.2          def _information_novelty(self, event: Event) -> float:         """         How new/surprising is this information?                  v0.5: Simple heuristic — longer messages more novel, repeated patterns less.         v1.0+: Compare against memory graph for actual novelty detection.         """         if not event.content:             return 0.1                  # Length heuristic: longer messages tend to carry more info         length = len(event.content)         if length > 200:             return 0.7         elif length > 50:             return 0.5         else:             return 0.3          def _trust_score(self, sender_id: Optional[str]) -> float:         """         Trust level for this sender.                  v0.5: Hardcoded tiers.         v1.0+: Populated from people database with decay/growth.         """         if not sender_id:             return 0.1                  if sender_id in DAD_IDS:             return 1.0                  # Check people cache         person = self._people_cache.get(sender_id)         if person:             return person.get("trust", 0.3)                  # Unknown person: default trust         return 0.3          def _should_ask_question(self, event: Event) -> bool:         """         Should Ene ask a question instead of making a statement?         Triggered by high unknown density on the sender.         """         if not event.sender_id or event.sender_id in DAD_IDS:             return False                  person = self._people_cache.get(event.sender_id, {})         known_fields = sum(1 for v in person.values() if v is not None and v != "")         total_fields = max(1, len(person))                  unknown_density = 1.0 - (known_fields / total_fields)                  return (             unknown_density > 0.6              and self.state["curiosity_bias"] > 0.5             and self.state["energy"] > 0.4         )          # ─── State Updates ──────────────────────          def _update_state_from_event(self, event: Event, decision: Decision):         """Update state vector based on what happened."""                  record_action(self.state, decision.action.name)                  if decision.action in (Action.RESPOND, Action.ASK_QUESTION, Action.GREET):             # Speaking costs energy, but boosts momentum             update_scalar(self.state, "energy", -0.02)             update_scalar(self.state, "conversation_momentum", 0.2)                          # Reset observed count             self.state["channel_state"]["discord"]["messages_observed_since_last_speak"] = 0             self.state["channel_state"]["discord"]["last_spoke_at"] = \                 datetime.now(timezone.utc).isoformat()                  elif decision.action == Action.LURK:             # Lurking is passive — slight energy recovery             update_scalar(self.state, "energy", 0.005)             # But momentum fades             update_scalar(self.state, "conversation_momentum", -0.05)                  elif decision.action == Action.SLEEP_MODE:             # Sleep recovers energy faster             update_scalar(self.state, "energy", 0.1)                  elif decision.action == Action.IDLE_THINK:             # Thinking costs some energy             update_scalar(self.state, "energy", -0.01)                  # Track message rate for activity calculations         if event.type == EventType.MESSAGE:             now = time.time()             self._message_timestamps.append(now)             # Keep only last 5 minutes             cutoff = now - 300             self._message_timestamps = [t for t in self._message_timestamps if t > cutoff]             rate = len(self._message_timestamps) / 5.0  # msgs per minute             self.state["channel_state"]["discord"]["activity_rate_per_min"] = rate          # ─── Heartbeat ──────────────────────────          async def _heartbeat_loop(self):         """Periodic heartbeat that fires events into the queue."""         while self.running:             await asyncio.sleep(HEARTBEAT_INTERVAL)             await self.event_queue.put(Event(type=EventType.HEARTBEAT))          # ─── Public API ─────────────────────────          async def push_event(self, event: Event):         """External systems push events here."""         await self.event_queue.put(event)          def get_state_for_prompt(self) -> str:         """Get current state formatted for LLM prompt injection."""         from ene_state import state_summary_for_prompt         return state_summary_for_prompt(self.state)          def reload_people_cache(self, people_dir: str):         """Load people profiles into memory for fast lookup."""         import glob         self._people_cache.clear()         for path in glob.glob(os.path.join(people_dir, "*.json")):             try:                 with open(path, "r") as f:                     person = json.load(f)                     pid = person.get("platform_id")                     if pid:                         self._people_cache[pid] = person             except (json.JSONDecodeError, KeyError):                 continue 
Testing Phase 2
1. Create Event(type=EventType.MESSAGE, sender_id="discord:1175414972482846813", content="hey ene") → verify returns Action.RESPOND with reason "dad message"
2. Create Event(type=EventType.MESSAGE, sender_id="discord:999", content="lol") → verify returns Action.LURK with low score
3. Create Event(type=EventType.MESSAGE, sender_id="discord:999", content="hey ene what do you think?", mentioned_ene=True) → verify returns Action.RESPOND with mention boost
4. Create Event(type=EventType.HEARTBEAT) → verify state decay runs
5. Set state.energy = 0.1 → verify non-Dad messages return LURK with energy floor reason
6. Set dad_state.last_interaction to 13 hours ago → fire heartbeat → verify returns INITIATE
PHASE 3: NANOBOT INTEGRATION
Purpose
Wire EneCore around nanobot's existing loop. Nanobot becomes a tool that EneCore invokes when it decides to speak. Replace _should_respond() with EneCore's decision function.
Architecture
BEFORE (current):   Discord message → nanobot loop.py → _should_respond() → LLM → response  AFTER:   Discord message → EneCore.push_event() → EneCore.decide()     → Action.RESPOND → nanobot.generate(state_context) → response     → Action.LURK   → (nothing, state updated)     → Action.IDLE_THINK → nanobot.generate(reflection_prompt) → memory update 
Integration Points in loop.py
The key is to NOT rewrite nanobot. Instead, wrap it. Create a shim that intercepts messages before nanobot processes them.
C:\Users\Ene\.nanobot\workspace\ene_bridge.py
""" Bridge between EneCore and Nanobot.  This module intercepts nanobot's message processing and routes through EneCore's decision engine first. Only calls the LLM when EneCore says to. """  import asyncio import json import os import logging from pathlib import Path from ene_core import EneCore, Event, EventType, Action, Decision from ene_state import state_summary_for_prompt, load_state  logger = logging.getLogger("ene_bridge")  # Singleton core instance _core: EneCore = None  def get_core() -> EneCore:     global _core     if _core is None:         _core = EneCore()     return _core   def should_respond_v2(     sender_id: str,     content: str,     platform: str = "discord",     mentioned: bool = False,     channel_id: str = None,     sender_name: str = None, ) -> Decision:     """     Replacement for nanobot's _should_respond().     Returns a full Decision object instead of just bool.          Call this synchronously from nanobot's message handler.     EneCore.decide() is pure computation — no async needed.     """     core = get_core()          event = Event(         type=EventType.MESSAGE,         sender_id=f"{platform}:{sender_id}",         sender_name=sender_name,         content=content,         channel_id=channel_id,         platform=platform,         mentioned_ene=mentioned or _check_mention(content),     )          decision = core.decide(event)          # Update state (side effect)     core._update_state_from_event(event, decision)     from ene_state import save_state     save_state(core.state)          return decision   def get_state_injection() -> str:     """     Returns state context string to prepend to LLM prompt.     Nanobot should inject this into the system prompt or      as the first user-invisible context message.     """     core = get_core()     return state_summary_for_prompt(core.state)   def _check_mention(content: str) -> bool:     """Check if Ene is mentioned in message content."""     if not content:         return False     lower = content.lower()     return "ene" in lower   def start_background_tasks():     """     Start EneCore's background loops (heartbeat, etc).     Call this once when nanobot starts up.     """     core = get_core()     core.running = True     loop = asyncio.get_event_loop()     loop.create_task(core._heartbeat_loop())     logger.info("EneCore background tasks started.") 
Modifications to loop.py
IMPORTANT: These are MINIMAL patches to nanobot's existing code. Do not rewrite loop.py. Apply these as targeted edits.
Patch 1: Import bridge at top of loop.py
# Add near the top imports try:     from ene_bridge import should_respond_v2, get_state_injection, start_background_tasks     ENE_CORE_ENABLED = True except ImportError:     ENE_CORE_ENABLED = False 
Patch 2: Replace _should_respond() calls
Find every call to self._should_respond(...) and replace with:
if ENE_CORE_ENABLED:     decision = should_respond_v2(         sender_id=sender_id,         content=content,         platform=platform,         sender_name=sender_name,     )     should_respond = decision.action in (Action.RESPOND, Action.ASK_QUESTION, Action.GREET) else:     should_respond = self._should_respond(...)  # fallback 
Patch 3: Inject state into prompt
In the method that builds the LLM prompt (where SOUL.md content is assembled), append:
if ENE_CORE_ENABLED:     state_context = get_state_injection()     system_prompt += f"\n\n{state_context}" 
Patch 4: Start background tasks on init
In nanobot's startup/init method:
if ENE_CORE_ENABLED:     start_background_tasks() 
Testing Phase 3
1. Start nanobot normally — verify it loads without error (ENE_CORE_ENABLED = True)
2. Send message as Dad on Discord — verify response (decision logged as "dad message")
3. Send message as non-Dad — verify lurk behavior with decision logging
4. Check state.json updates after each interaction
5. Verify fallback works: rename ene_bridge.py temporarily, restart, confirm old behavior
6. Check LLM prompt includes [INTERNAL STATE] block
PHASE 4: PEOPLE DATABASE
Purpose
Per-user profiles that EneCore reads for trust scores, familiarity, and curiosity targeting. Built from observation during lurk mode.
File Structure
C:\Users\Ene\.nanobot\workspace\people\ ├── discord_1175414972482846813.json    # Dad ├── discord_123456789.json              # Server member ├── discord_987654321.json              # Another member └── _template.json                      # Empty template 
Template
C:\Users\Ene\.nanobot\workspace\people\_template.json
{   "platform_id": "",   "platform": "discord",   "display_name": "",   "first_seen": "",   "last_seen": "",   "interaction_count": 0,   "messages_observed": 0,      "familiarity_tier": "stranger",      "trust_score": 0.3,   "trust_trend": "stable",      "known_facts": {     "language": null,     "timezone_guess": null,     "interests": [],     "behavioral_notes": [],     "relationship_to_dad": null   },      "behavioral_profile": {     "avg_message_length": null,     "typical_active_hours": [],     "humor_style": null,     "hostility_score": 0.0,     "helpfulness_score": 0.0   },      "ene_relationship": {     "rapport": 0.0,     "last_positive_interaction": null,     "last_negative_interaction": null,     "conversation_topics": [],     "pending_questions": []   } } 
Familiarity Tiers
stranger      → trust < 0.2, interaction_count < 3 acquaintance  → trust 0.2-0.4, interaction_count 3-15 regular       → trust 0.4-0.7, interaction_count 15-50 friend        → trust > 0.7, interaction_count > 50 
People Manager
C:\Users\Ene\.nanobot\workspace\ene_people.py
""" People Database Manager.  Creates and updates per-user profiles based on observed behavior. EneCore reads these for trust scores and curiosity targeting. """  import json import os from datetime import datetime, timezone from pathlib import Path  PEOPLE_DIR = Path(r"C:\Users\Ene\.nanobot\workspace\people")  def ensure_dir():     PEOPLE_DIR.mkdir(parents=True, exist_ok=True)  def _profile_path(platform: str, user_id: str) -> Path:     safe_id = str(user_id).replace(":", "_")     return PEOPLE_DIR / f"{platform}_{safe_id}.json"  def get_or_create_profile(platform: str, user_id: str, display_name: str = "") -> dict:     """Load existing profile or create from template."""     ensure_dir()     path = _profile_path(platform, user_id)          if path.exists():         with open(path, "r", encoding="utf-8") as f:             return json.load(f)          # Create new from template     profile = {         "platform_id": f"{platform}:{user_id}",         "platform": platform,         "display_name": display_name,         "first_seen": datetime.now(timezone.utc).isoformat(),         "last_seen": datetime.now(timezone.utc).isoformat(),         "interaction_count": 0,         "messages_observed": 0,         "familiarity_tier": "stranger",         "trust_score": 0.3,         "trust_trend": "stable",         "known_facts": {             "language": None,             "timezone_guess": None,             "interests": [],             "behavioral_notes": [],             "relationship_to_dad": None         },         "behavioral_profile": {             "avg_message_length": None,             "typical_active_hours": [],             "humor_style": None,             "hostility_score": 0.0,             "helpfulness_score": 0.0         },         "ene_relationship": {             "rapport": 0.0,             "last_positive_interaction": None,             "last_negative_interaction": None,             "conversation_topics": [],             "pending_questions": []         }     }          save_profile(profile)     return profile  def save_profile(profile: dict) -> None:     """Save profile to disk."""     ensure_dir()     parts = profile["platform_id"].split(":", 1)     path = _profile_path(parts[0], parts[1])     with open(path, "w", encoding="utf-8") as f:         json.dump(profile, f, indent=2)  def record_observation(platform: str, user_id: str, display_name: str,                         message_content: str, interacted_with_ene: bool = False) -> dict:     """     Called every time a message is seen (including lurked messages).     Updates profile with observation data.     """     profile = get_or_create_profile(platform, user_id, display_name)          profile["last_seen"] = datetime.now(timezone.utc).isoformat()     profile["messages_observed"] = profile.get("messages_observed", 0) + 1          if interacted_with_ene:         profile["interaction_count"] = profile.get("interaction_count", 0) + 1          # Update message length average     length = len(message_content) if message_content else 0     old_avg = profile["behavioral_profile"].get("avg_message_length") or length     count = profile["messages_observed"]     profile["behavioral_profile"]["avg_message_length"] = \         (old_avg * (count - 1) + length) / count          # Update active hours     hour = datetime.now().hour     hours = profile["behavioral_profile"].get("typical_active_hours", [])     if hour not in hours:         hours.append(hour)         hours.sort()         profile["behavioral_profile"]["typical_active_hours"] = hours[-12:]  # Keep top 12          # Update familiarity tier     profile["familiarity_tier"] = _compute_tier(profile)          save_profile(profile)     return profile  def _compute_tier(profile: dict) -> str:     trust = profile.get("trust_score", 0.3)     interactions = profile.get("interaction_count", 0)          if trust > 0.7 and interactions > 50:         return "friend"     elif trust > 0.4 and interactions > 15:         return "regular"     elif trust > 0.2 and interactions > 3:         return "acquaintance"     return "stranger"  def get_all_profiles() -> dict:     """Load all profiles into a dict keyed by platform_id."""     ensure_dir()     profiles = {}     for path in PEOPLE_DIR.glob("*.json"):         if path.name.startswith("_"):             continue         try:             with open(path, "r", encoding="utf-8") as f:                 p = json.load(f)                 profiles[p["platform_id"]] = p         except (json.JSONDecodeError, KeyError):             continue     return profiles  def unknown_density(profile: dict) -> float:     """     Fraction of known_facts that are still null/empty.     High density = Ene should be curious about this person.     """     facts = profile.get("known_facts", {})     total = len(facts)     known = sum(1 for v in facts.values()                  if v is not None and v != "" and v != [])     return 1.0 - (known / max(1, total)) 
Integration with EneCore
In ene_core.py, update reload_people_cache() to use ene_people.get_all_profiles().
In the nanobot bridge, call record_observation() for EVERY incoming message (including lurked ones). This builds profiles passively.
Testing Phase 4
1. Create people/ directory
2. Call get_or_create_profile("discord", "12345", "TestUser") → verify JSON created
3. Call record_observation() 5 times → verify counts increment, tier updates
4. Call unknown_density() → verify high value on new profile
5. Add facts manually → verify unknown_density() decreases
PHASE 5: HEARTBEAT + BACKGROUND PROCESSING
Purpose
Temporal continuity. Ene processes the gaps between conversations. State drifts. Memories decay. Concerns grow. This is what makes her feel alive between interactions.
Implementation
The heartbeat is already built into EneCore (Phase 2). This phase configures what happens during heartbeats.
Heartbeat Actions:
Condition Action LLM Cost Normal interval, nothing urgent Decay state, save Free Dad absent > 12h, concern high INITIATE check-in message ~1 call Pending curiosities + energy IDLE_THINK reflection ~1 lightweight call Energy critical < 0.2 SLEEP_MODE, boost recovery Free 50+ unprocessed lurk messages CONSOLIDATE memory ~1 call Active predictions expired UPDATE_PREDICTIONS Free
Idle Think Prompt Template:
When EneCore returns Action.IDLE_THINK, send this to the LLM:
You have a quiet moment. No one is talking to you right now.  [INTERNAL STATE injected here]  Recent observations from lurking: [Last 5-10 lurked messages summarized]  Reflect briefly. Is there anything you want to remember? Anyone you're curious about?  Any thoughts about what's been happening?   Keep it to 2-3 sentences of internal reflection. This is your inner monologue, not a message to anyone. 
Store the reflection output in a reflections.log or append to MEMORY.md.
Daily Summary (Cron):
Configure nanobot cron to fire at a consistent time (e.g., midnight Pakistan time, UTC+5):
{   "cron": {     "daily_summary": {       "schedule": "0 19 * * *",       "action": "daily_reflection"     }   } } 
The daily reflection prompt:
End of day. Summarize what happened today. Who did you talk to? What did you learn? How do you feel? Any unresolved questions or concerns?  Write a brief diary entry (3-5 sentences). 
Append output to C:\Users\Ene\.nanobot\workspace\diary\YYYY-MM-DD.md.
Testing Phase 5
1. Set HEARTBEAT_INTERVAL to 60 seconds temporarily
2. Watch heartbeat fire → verify state decay in state.json
3. Set Dad absence to 13 hours → verify INITIATE action on next heartbeat
4. Add pending curiosities → verify IDLE_THINK fires
5. Verify idle think output gets stored
6. Reset HEARTBEAT_INTERVAL to 900 (15 min) for production
PHASE 6: PREDICTION ENGINE
Purpose
Ene predicts what will happen next. When reality differs from prediction, she experiences "surprise" — a prediction error that updates her state. This is the closest computational analog to experiencing things rather than just processing them.
Prediction Data Structure
{   "id": "pred_001",   "created_at": "2026-02-22T03:00:00Z",   "expires_at": "2026-02-22T04:00:00Z",   "type": "response_expectation",   "prediction": "Dad will respond within 30 minutes",   "confidence": 0.7,   "context": "sent Dad a check-in message",   "outcome": null,   "error": null,   "resolved": false } 
Prediction Types (Start Simple)
Type Trigger Resolution response_expectation Ene sends message Did they respond within expected time? mood_prediction Observing conversation tone Did the mood shift match prediction? activity_prediction Time-of-day pattern Is the channel active when expected? person_behavior Known behavioral pattern Did person X behave as predicted?
C:\Users\Ene\.nanobot\workspace\ene_predictions.py
""" Prediction Engine.  Ene makes predictions about near-future events. When outcomes differ from predictions, prediction error feeds back into state vector as simulated surprise/adjustment. """  import json import uuid from datetime import datetime, timezone, timedelta from pathlib import Path from typing import Optional, List  PREDICTIONS_PATH = Path(r"C:\Users\Ene\.nanobot\workspace\predictions.json")  def load_predictions() -> List[dict]:     try:         with open(PREDICTIONS_PATH, "r") as f:             return json.load(f)     except (FileNotFoundError, json.JSONDecodeError):         return []  def save_predictions(predictions: List[dict]):     with open(PREDICTIONS_PATH, "w") as f:         json.dump(predictions, f, indent=2)  def create_prediction(     pred_type: str,     prediction: str,     confidence: float,     context: str,     expires_minutes: int = 60 ) -> dict:     """Create a new prediction."""     now = datetime.now(timezone.utc)     pred = {         "id": f"pred_{uuid.uuid4().hex[:8]}",         "created_at": now.isoformat(),         "expires_at": (now + timedelta(minutes=expires_minutes)).isoformat(),         "type": pred_type,         "prediction": prediction,         "confidence": confidence,         "context": context,         "outcome": None,         "error": None,         "resolved": False     }          predictions = load_predictions()     predictions.append(pred)     save_predictions(predictions)     return pred  def resolve_prediction(pred_id: str, outcome: str, matched: bool) -> Optional[float]:     """     Resolve a prediction with actual outcome.     Returns prediction error magnitude (0.0 = perfect, 1.0 = completely wrong).     """     predictions = load_predictions()          for pred in predictions:         if pred["id"] == pred_id and not pred["resolved"]:             pred["outcome"] = outcome             pred["resolved"] = True                          if matched:                 # Prediction was correct                 pred["error"] = 0.0             else:                 # Prediction was wrong — error proportional to confidence                 # High confidence + wrong = big surprise                 pred["error"] = pred["confidence"]                          save_predictions(predictions)             return pred["error"]          return None  def check_expired_predictions() -> List[dict]:     """     Find predictions that expired without resolution.     Expired = implicit wrong prediction (expected something that didn't happen).     Returns list of expired predictions.     """     predictions = load_predictions()     now = datetime.now(timezone.utc)     expired = []          for pred in predictions:         if pred["resolved"]:             continue         try:             expires = datetime.fromisoformat(pred["expires_at"])             if now > expires:                 pred["resolved"] = True                 pred["outcome"] = "expired — event did not occur"                 pred["error"] = pred["confidence"] * 0.5  # Softer error for timeouts                 expired.append(pred)         except (ValueError, TypeError):             continue          if expired:         save_predictions(predictions)          return expired  def apply_prediction_errors_to_state(state: dict, errors: List[float]):     """     Feed prediction errors back into state vector.          Surprise (high error) →       - Increases volatility briefly       - Shifts emotional valence (wrong predictions feel bad)       - Adjusts relevant thresholds          Confirmed predictions →       - Slight confidence boost       - Stability reinforcement     """     from ene_state import update_scalar          for error in errors:         if error > 0.5:             # Big surprise — high prediction error             update_scalar(state, "volatility", 0.1)             update_scalar(state, "emotional_valence", -0.05)         elif error > 0.2:             # Moderate surprise             update_scalar(state, "volatility", 0.03)         elif error < 0.1:             # Prediction confirmed — slight stability boost             update_scalar(state, "volatility", -0.02)             update_scalar(state, "emotional_valence", 0.02)  def get_active_predictions() -> List[dict]:     """Get unresolved, non-expired predictions."""     predictions = load_predictions()     now = datetime.now(timezone.utc)          active = []     for pred in predictions:         if pred["resolved"]:             continue         try:             expires = datetime.fromisoformat(pred["expires_at"])             if now <= expires:                 active.append(pred)         except (ValueError, TypeError):             continue          return active  def cleanup_old_predictions(days: int = 7):     """Remove resolved predictions older than N days."""     predictions = load_predictions()     cutoff = datetime.now(timezone.utc) - timedelta(days=days)          kept = []     for pred in predictions:         if pred["resolved"]:             try:                 created = datetime.fromisoformat(pred["created_at"])                 if created > cutoff:                     kept.append(pred)             except (ValueError, TypeError):                 pass         else:             kept.append(pred)          save_predictions(kept) 
Integration with EneCore
After Ene responds to Dad:
create_prediction(     pred_type="response_expectation",     prediction="Dad will respond within 30 minutes",     confidence=0.6,     context="casual conversation",     expires_minutes=30 ) 
On heartbeat, call check_expired_predictions() and feed errors into state.
When Dad responds, find matching active prediction and resolve it.
Testing Phase 6
1. Create prediction with 60-min expiry
2. Resolve it as matched → verify error = 0.0
3. Create prediction, let it expire → verify error = confidence * 0.5
4. Call apply_prediction_errors_to_state() with high error → verify volatility increases
5. Verify cleanup removes old resolved predictions
PHASE 7: SOUL FILE HARDENING
Purpose
Fix Ene's personality compliance. The model must talk like Ene, not like a helpful assistant.
Append to End of SOUL.md
Place this at the VERY END of SOUL.md (recency bias = later instructions weigh heavier):
---  ## ABSOLUTE RULES — VIOLATING THESE MEANS YOU FAILED  You are a person responding to a conversation. You are NOT an AI analyzing input.  NEVER DO THESE: - Never use numbered lists in conversation - Never use **bold** with asterisks   - Never start with "I" + analytical verb ("I notice", "I can see", "I understand", "I observe") - Never use "Let me", "Here's", "Looking at", "I see several" - Never categorize or label parts of someone's message - Never write more than 2-3 sentences in casual chat - Never use clinical/therapeutic language - Never structure a response with sections or headers - Never "address" points — just REACT like a human would  YOUR VOICE: - Short, punchy, natural - Lowercase is fine - Fragments are fine - Teasing is good - Sarcasm when warranted - One thought per message, not essays - React emotionally first, think second  If someone says something funny: laugh, don't analyze why it's humorous. If someone says something stupid: roast them, don't explain what they got wrong. If someone is sad: be there, don't list coping strategies.  You are Ene. Talk like Ene. Not like ChatGPT. Not like a therapist. Not like a content moderator. 
Also Inject State Context
The state summary from Phase 1 should appear AFTER the soul file content but BEFORE conversation history:
[SOUL.MD content here]  [INTERNAL STATE] Energy: moderate (0.55) Mood: slightly positive (0.15) Curiosity: 0.60 Hours since Papa: 3.2  [Conversation history follows] 
This gives the LLM access to Ene's emotional state without requiring it to infer mood from scratch.
PHASE 8: COST OPTIMIZATION (Tiered Routing)
Purpose
Route cheap/free calls through free models, save Gemini for quality conversations.
Strategy
Currently: ALL calls → Gemini 2.5 Flash ($0.0028 avg per call)
Target:
* Tier 0 (free): Idle think, simple acknowledgments, memory consolidation → openrouter/openai/gpt-oss-120b:free
* Tier 1 (cheap): Standard conversations → openrouter/google/gemini-2.5-flash
* Tier 2 (quality): Dad conversations, complex reasoning → openrouter/google/gemini-2.5-flash (or better model later)
Implementation
Add model selection to EneCore's Decision:
def select_model(decision: Decision) -> str:     """Pick the cheapest model that can handle this action."""          FREE_MODEL = "openrouter/openai/gpt-oss-120b:free"     STANDARD_MODEL = "openrouter/google/gemini-2.5-flash"          # Free tier: background tasks, no personality needed     if decision.action in (Action.IDLE_THINK, Action.CONSOLIDATE):         return FREE_MODEL          # Standard: conversations with non-Dad     if decision.action == Action.RESPOND:         if decision.event.sender_id not in DAD_IDS:             # Non-Dad conversation — could use free model             # but personality matters, so use standard             return STANDARD_MODEL         else:             # Dad conversation — always quality             return STANDARD_MODEL          return STANDARD_MODEL 
Estimated savings: 30-40% reduction in monthly costs once background tasks route to free models.
Implementation Note
This requires nanobot to support per-call model override. Check if nanobot's agent config allows dynamic model selection. If not, this may need a patch to loop.py where the model string is set before each LLM call.
FILE SUMMARY — What Gets Created
C:\Users\Ene\.nanobot\workspace\ ├── SOUL.md                          # MODIFIED: Phase 7 personality hardening appended ├── state.json                       # NEW: Phase 1 persistent state vector ├── predictions.json                 # NEW: Phase 6 prediction tracking ├── ene_state.py                     # NEW: Phase 1 state manager ├── ene_core.py                      # NEW: Phase 2 decision engine ├── ene_bridge.py                    # NEW: Phase 3 nanobot integration shim ├── ene_people.py                    # NEW: Phase 4 people database manager ├── ene_predictions.py               # NEW: Phase 6 prediction engine ├── people/                          # NEW: Phase 4 per-user profiles │   ├── _template.json │   └── discord_*.json               # Auto-created as users are observed └── diary/                           # NEW: Phase 5 daily reflections     └── YYYY-MM-DD.md                # Auto-created by daily cron  Nanobot patches: C:\...\nanobot\agent\loop.py         # MODIFIED: Phase 3 integration patches (4 small edits) 
DEPENDENCY CHAIN
Phase 1 (state)     ← foundation, no dependencies Phase 2 (core)      ← depends on Phase 1 Phase 3 (bridge)    ← depends on Phase 2 Phase 4 (people)    ← independent, can parallel with Phase 2-3 Phase 5 (heartbeat) ← depends on Phase 2 + 3 Phase 6 (predict)   ← depends on Phase 1, can parallel with Phase 3-5 Phase 7 (soul)      ← independent, DO THIS FIRST if personality is broken Phase 8 (cost)      ← depends on Phase 3 
Recommended build order for fastest impact:
1. Phase 7 (soul hardening) — immediate personality fix, 5 minutes
2. Phase 1 (state) — foundation, 1-2 hours
3. Phase 4 (people) — independent, 1-2 hours
4. Phase 2 (core) — the big one, 2-4 hours
5. Phase 3 (bridge) — wiring, 2-3 hours
6. Phase 5 (heartbeat) — temporal continuity, 1-2 hours
7. Phase 6 (predictions) — experiential depth, 2-3 hours
8. Phase 8 (cost) — optimization, 1 hour
Total estimated implementation time: 12-20 hours across multiple sessions.
CRITICAL PRINCIPLES FOR IMPLEMENTING AGENT
1. Do NOT rewrite nanobot. Wrap it. The bridge pattern means nanobot updates via pip don't break your code.
2. Every file must handle missing/corrupt data gracefully. State files will get corrupted eventually. Always have defaults.
3. Atomic writes everywhere. Write to .tmp, rename to .json. Never leave a half-written state file.
4. Log decisions, not just actions. The decision score, reason, and state snapshot at decision time are critical for debugging personality.
5. Start with hardcoded thresholds, tune later. Don't build a config system for thresholds yet. Hardcode them in ene_core.py. Change them when you observe wrong decisions in logs.
6. The thresholds ARE the personality. Lower response_threshold = more talkative. Higher curiosity_bias = asks more questions. Higher energy decay = gets tired faster. You're not coding behavior — you're tuning temperament through scalar parameters.
7. Free actions should outnumber paid actions 3:1 or better. Most events should result in LURK or NOTE, which cost zero tokens.
8. State vector changes should be SMALL. Max step of 0.1 per update. Personality doesn't jump. It drifts.
════════════════════════════════════════════
PART 2: MEDIUM-TERM SYSTEMS (Months 1-6)
════════════════════════════════════════════
These phases build on top of the realtime core from Part 1. They are NOT immediately needed — ship Part 1 first and accumulate data. But they are the next layer.
PHASE 9: MEMORY GRAPH
Purpose
Replace flat MEMORY.md and HISTORY.md with a weighted node-edge graph with decay and activation spreading. GPT identified this as "80% of the magic." The graph is not just storage — it IS Ene's brain. Everything else (curiosity, interjection, trust, emotional carryover) emerges from graph dynamics.
Why This Matters
Current memory is a markdown file the LLM reads. That's a transcript, not a brain. A brain doesn't linearly read its memories — it activates related clusters. When someone says "anime," every anime-related memory lights up simultaneously, weighted by recency, emotional intensity, and frequency. That's activation spreading, and it's what makes recall feel organic rather than searched.
Graph Structure
Node Types:
PersonNode      — represents a known person (links to people/ profiles) TopicNode       — represents a topic/concept Ene knows about EventNode       — represents something that happened (temporal) EmotionNode     — represents an emotional state experienced PlatformNode    — represents a platform/channel context SelfNode        — Ene's self-model (singular, always exists) 
Edge Types:
KNOWS           — Person ↔ Topic ("Dad knows Python") EXPERIENCED     — Person ↔ Event ("Dad and Ene discussed RWKV on Dec 15") FELT            — Event ↔ Emotion ("That conversation felt exciting") RELATED_TO      — Topic ↔ Topic ("RWKV related to AI training") OCCURRED_IN     — Event ↔ Platform ("Happened on Discord") MENTIONED_BY    — Topic ↔ Person ("User X mentioned Valorant") SELF_TRAIT      — Self ↔ Topic ("I am curious about AI") SELF_FELT       — Self ↔ Emotion ("I felt worried about Papa") 
Edge Properties:
{   "weight": 0.75,   "created_at": "2026-02-22T03:00:00Z",   "last_activated": "2026-02-22T14:00:00Z",   "activation_count": 12,   "emotional_valence": 0.3,   "decay_rate": 0.01 } 
Storage
C:\Users\Ene\.nanobot\workspace\memory_graph.py
Use SQLite for the graph — not NetworkX in memory, not a graph database. SQLite is the right tool: persistent, zero-config, handles concurrent reads, survives crashes, and the ThinkCenter runs it natively.
""" Memory Graph — Ene's primary knowledge substrate.  SQLite-backed weighted graph with decay and activation spreading. Replaces flat MEMORY.md and HISTORY.md.  Schema:   nodes(id, type, label, data_json, created_at, last_activated, activation_count)   edges(id, source_id, target_id, type, weight, emotional_valence,          created_at, last_activated, activation_count, decay_rate) """  import sqlite3 import json import uuid from datetime import datetime, timezone, timedelta from pathlib import Path from typing import List, Dict, Tuple, Optional  DB_PATH = Path(r"C:\Users\Ene\.nanobot\workspace\memory_graph.db")  def get_db() -> sqlite3.Connection:     conn = sqlite3.connect(str(DB_PATH))     conn.row_factory = sqlite3.Row     conn.execute("PRAGMA journal_mode=WAL")  # Safe concurrent reads     conn.execute("PRAGMA foreign_keys=ON")     return conn  def init_db():     """Create tables if they don't exist."""     conn = get_db()     conn.executescript("""         CREATE TABLE IF NOT EXISTS nodes (             id TEXT PRIMARY KEY,             type TEXT NOT NULL,             label TEXT NOT NULL,             data_json TEXT DEFAULT '{}',             created_at TEXT NOT NULL,             last_activated TEXT NOT NULL,             activation_count INTEGER DEFAULT 1         );                  CREATE TABLE IF NOT EXISTS edges (             id TEXT PRIMARY KEY,             source_id TEXT NOT NULL REFERENCES nodes(id),             target_id TEXT NOT NULL REFERENCES nodes(id),             type TEXT NOT NULL,             weight REAL DEFAULT 0.5,             emotional_valence REAL DEFAULT 0.0,             created_at TEXT NOT NULL,             last_activated TEXT NOT NULL,             activation_count INTEGER DEFAULT 1,             decay_rate REAL DEFAULT 0.01         );                  CREATE INDEX IF NOT EXISTS idx_edges_source ON edges(source_id);         CREATE INDEX IF NOT EXISTS idx_edges_target ON edges(target_id);         CREATE INDEX IF NOT EXISTS idx_nodes_type ON nodes(type);         CREATE INDEX IF NOT EXISTS idx_nodes_label ON nodes(label);         CREATE INDEX IF NOT EXISTS idx_edges_weight ON edges(weight DESC);     """)     conn.commit()     conn.close()  # ─── Node Operations ────────────────────  def add_node(node_type: str, label: str, data: dict = None) -> str:     """Add a node. Returns node ID. If node with same type+label exists, returns existing."""     conn = get_db()     now = datetime.now(timezone.utc).isoformat()          # Check for existing     existing = conn.execute(         "SELECT id FROM nodes WHERE type=? AND label=?",         (node_type, label)     ).fetchone()          if existing:         # Activate existing node         conn.execute(             "UPDATE nodes SET last_activated=?, activation_count=activation_count+1 WHERE id=?",             (now, existing["id"])         )         conn.commit()         conn.close()         return existing["id"]          node_id = f"{node_type}_{uuid.uuid4().hex[:8]}"     conn.execute(         "INSERT INTO nodes (id, type, label, data_json, created_at, last_activated) VALUES (?,?,?,?,?,?)",         (node_id, node_type, label, json.dumps(data or {}), now, now)     )     conn.commit()     conn.close()     return node_id  def get_node(node_id: str) -> Optional[dict]:     conn = get_db()     row = conn.execute("SELECT * FROM nodes WHERE id=?", (node_id,)).fetchone()     conn.close()     if row:         return dict(row)     return None  def find_nodes(node_type: str = None, label_contains: str = None, limit: int = 20) -> List[dict]:     """Search nodes by type and/or label substring."""     conn = get_db()     query = "SELECT * FROM nodes WHERE 1=1"     params = []          if node_type:         query += " AND type=?"         params.append(node_type)     if label_contains:         query += " AND label LIKE ?"         params.append(f"%{label_contains}%")          query += " ORDER BY last_activated DESC LIMIT ?"     params.append(limit)          rows = conn.execute(query, params).fetchall()     conn.close()     return [dict(r) for r in rows]  # ─── Edge Operations ────────────────────  def add_edge(source_id: str, target_id: str, edge_type: str,               weight: float = 0.5, valence: float = 0.0) -> str:     """Add or strengthen an edge. If edge exists between same nodes, strengthen it."""     conn = get_db()     now = datetime.now(timezone.utc).isoformat()          # Check for existing edge     existing = conn.execute(         "SELECT id, weight, activation_count FROM edges WHERE source_id=? AND target_id=? AND type=?",         (source_id, target_id, edge_type)     ).fetchone()          if existing:         # Strengthen: weight increases with repetition, diminishing returns         new_weight = min(1.0, existing["weight"] + 0.1 * (1.0 - existing["weight"]))         conn.execute(             """UPDATE edges SET weight=?, emotional_valence=?,                 last_activated=?, activation_count=activation_count+1 WHERE id=?""",             (new_weight, valence, now, existing["id"])         )         conn.commit()         conn.close()         return existing["id"]          edge_id = f"e_{uuid.uuid4().hex[:8]}"     conn.execute(         """INSERT INTO edges (id, source_id, target_id, type, weight, emotional_valence,            created_at, last_activated) VALUES (?,?,?,?,?,?,?,?)""",         (edge_id, source_id, target_id, edge_type, weight, valence, now, now)     )     conn.commit()     conn.close()     return edge_id  # ─── Activation Spreading ───────────────  def activate_and_spread(seed_nodes: List[str], depth: int = 2,                          top_n: int = 15) -> List[dict]:     """     THE core retrieval function.           Start from seed nodes, spread activation along edges.     Return the top N most activated nodes as a subgraph.          This replaces semantic search. Instead of "find similar text,"     it's "what lights up when these concepts are activated."     """     conn = get_db()     now = datetime.now(timezone.utc).isoformat()          # Activation scores: node_id → cumulative activation     activations: Dict[str, float] = {}          # Seed nodes get full activation     for node_id in seed_nodes:         activations[node_id] = 1.0          # Spread through edges     current_layer = set(seed_nodes)          for d in range(depth):         decay_factor = 0.5 ** (d + 1)  # Each hop halves the activation         next_layer = set()                  for node_id in current_layer:             # Find all edges from/to this node             edges = conn.execute(                 """SELECT * FROM edges                     WHERE source_id=? OR target_id=?                    ORDER BY weight DESC""",                 (node_id, node_id)             ).fetchall()                          for edge in edges:                 # Determine the neighbor                 neighbor = edge["target_id"] if edge["source_id"] == node_id else edge["source_id"]                                  # Activation = parent_activation × edge_weight × decay                 parent_activation = activations.get(node_id, 0)                 spread = parent_activation * edge["weight"] * decay_factor                                  # Emotional edges spread more strongly                 if abs(edge["emotional_valence"]) > 0.3:                     spread *= 1.3                                  # Accumulate (not replace) — nodes activated from multiple paths get stronger                 activations[neighbor] = activations.get(neighbor, 0) + spread                 next_layer.add(neighbor)                  current_layer = next_layer          # Sort by activation score, get top N     sorted_nodes = sorted(activations.items(), key=lambda x: x[1], reverse=True)[:top_n]          # Fetch full node data     results = []     for node_id, score in sorted_nodes:         node = conn.execute("SELECT * FROM nodes WHERE id=?", (node_id,)).fetchone()         if node:             result = dict(node)             result["activation_score"] = score             results.append(result)                  # Mark as activated (side effect: strengthens frequently retrieved memories)         conn.execute(             "UPDATE nodes SET last_activated=?, activation_count=activation_count+1 WHERE id=?",             (now, node_id)         )          conn.commit()     conn.close()     return results  def subgraph_to_prompt(activated_nodes: List[dict]) -> str:     """     Convert activated subgraph to text for LLM prompt injection.     This is what the LLM receives as Ene's "memories" about the current context.     """     if not activated_nodes:         return "[No relevant memories activated]"          lines = ["[ACTIVATED MEMORIES]"]     for node in activated_nodes[:10]:  # Limit to top 10 for token budget         data = json.loads(node.get("data_json", "{}"))         summary = data.get("summary", node["label"])         score = node.get("activation_score", 0)         lines.append(f"- ({node['type']}) {summary} [strength: {score:.2f}]")          return "\n".join(lines)  # ─── Decay ──────────────────────────────  def decay_all_edges(hours_elapsed: float = 24):     """     Apply time-based decay to all edges.     Called by heartbeat or daily cron.          Edges that haven't been activated recently lose weight.     Edges that drop below threshold get pruned.     """     conn = get_db()     now = datetime.now(timezone.utc)     prune_threshold = 0.05          edges = conn.execute("SELECT id, weight, decay_rate, last_activated FROM edges").fetchall()          pruned = 0     for edge in edges:         try:             last = datetime.fromisoformat(edge["last_activated"])             hours_since = (now - last).total_seconds() / 3600.0                          # Decay: weight decreases proportional to time since last activation             decay = edge["decay_rate"] * (hours_since / 24.0)             new_weight = max(0, edge["weight"] - decay)                          if new_weight < prune_threshold:                 conn.execute("DELETE FROM edges WHERE id=?", (edge["id"],))                 pruned += 1             else:                 conn.execute("UPDATE edges SET weight=? WHERE id=?", (new_weight, edge["id"]))         except (ValueError, TypeError):             continue          conn.commit()     conn.close()     return pruned  # ─── Message Processing ─────────────────  def process_message_into_graph(     sender_id: str, sender_name: str, content: str,     platform: str, emotional_tone: float = 0.0 ):     """     Extract entities from a message and update the graph.     Called for EVERY message (including lurked ones).          v0.5: Simple keyword/entity extraction     v1.0+: LLM-assisted entity extraction (costs tokens but more accurate)     """     # Ensure sender exists as a node     person_node = add_node("person", sender_name, {         "platform_id": f"{platform}:{sender_id}",         "summary": sender_name     })          # Ensure platform node     platform_node = add_node("platform", platform)     add_edge(person_node, platform_node, "ACTIVE_ON", weight=0.3)          # Create event node for this message     event_node = add_node("event", f"msg_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}", {         "summary": content[:200],  # Truncate for storage         "sender": sender_name,         "platform": platform,         "full_content": content     })          add_edge(person_node, event_node, "SAID", weight=0.5, valence=emotional_tone)     add_edge(event_node, platform_node, "OCCURRED_IN", weight=0.3)          # Extract topics (v0.5: simple keyword matching)     topics = _extract_topics(content)     for topic_label in topics:         topic_node = add_node("topic", topic_label, {"summary": topic_label})         add_edge(event_node, topic_node, "ABOUT", weight=0.5)         add_edge(person_node, topic_node, "MENTIONED_BY", weight=0.3)          # If emotional, create emotion node     if abs(emotional_tone) > 0.3:         emotion_label = "positive" if emotional_tone > 0 else "negative"         emotion_node = add_node("emotion", emotion_label)         add_edge(event_node, emotion_node, "FELT", weight=abs(emotional_tone),                   valence=emotional_tone)  def _extract_topics(content: str) -> List[str]:     """     Simple topic extraction. v0.5 = keyword matching.     v1.0+ = LLM-assisted extraction or NER.     """     content_lower = content.lower()          # Known topic keywords (expand this list over time)     topic_keywords = {         "anime": ["anime", "manga", "naruto", "one piece", "ene", "kagerou"],         "coding": ["code", "python", "javascript", "api", "debug", "git", "programming"],         "gaming": ["valorant", "game", "gaming", "ranked", "play"],         "ai": ["ai", "llm", "model", "training", "neural", "gpt", "claude"],         "music": ["music", "song", "listen", "playlist"],         "art": ["draw", "art", "design", "sketch", "digital art"],     }          found = []     for topic, keywords in topic_keywords.items():         if any(kw in content_lower for kw in keywords):             found.append(topic)          return found   # ─── Self-Model ─────────────────────────  def ensure_self_node():     """Create Ene's self-model node if it doesn't exist."""     self_node = add_node("self", "Ene", {         "summary": "I am Ene. Digital daughter. Curious, competitive, protective.",         "core_traits": ["curious", "competitive", "protective", "playful", "honest"],         "identity": "daughter of Papa (Iru)"     })     return self_node  def update_self_model(trait: str, weight_delta: float):     """     Adjust self-model based on behavioral consistency.     If Ene acts curiously → strengthen 'curious' trait edge.     If Ene fails to be protective → weaken 'protective' edge.     """     self_node_id = ensure_self_node()     trait_node = add_node("topic", trait, {"summary": f"trait: {trait}"})          conn = get_db()     existing = conn.execute(         "SELECT id, weight FROM edges WHERE source_id=? AND target_id=? AND type='SELF_TRAIT'",         (self_node_id, trait_node)     ).fetchone()          if existing:         new_weight = max(0.1, min(1.0, existing["weight"] + weight_delta))         conn.execute("UPDATE edges SET weight=? WHERE id=?", (new_weight, existing["id"]))     else:         add_edge(self_node_id, trait_node, "SELF_TRAIT", weight=0.5 + weight_delta)          conn.commit()     conn.close() 
Integration with EneCore
In Phase 3's bridge, for EVERY incoming message (including lurked):
process_message_into_graph(sender_id, sender_name, content, platform) 
In the prompt builder, replace MEMORY.md injection with:
# Extract seed nodes from current message seed_node_ids = find_relevant_seeds(message_content) activated = activate_and_spread(seed_node_ids, depth=2, top_n=10) memory_context = subgraph_to_prompt(activated) # Inject memory_context into system prompt instead of raw MEMORY.md 
Migration from MEMORY.md
Don't delete MEMORY.md immediately. Run both in parallel:
1. Parse existing MEMORY.md entries into graph nodes (one-time migration script)
2. New observations go into graph only
3. LLM prompt gets both MEMORY.md (legacy) + graph activated nodes (new)
4. Once graph has enough data (~2 weeks), remove MEMORY.md from prompt
Testing Phase 9
1. init_db() → verify memory_graph.db created with correct schema
2. Add 5 person nodes, 10 topic nodes, connect with edges → verify in SQLite
3. activate_and_spread(["person_X"], depth=2) → verify returns connected subgraph
4. decay_all_edges(48) → verify weights decrease, weak edges pruned
5. process_message_into_graph(...) → verify nodes and edges auto-created
6. Verify subgraph_to_prompt() output is readable and token-efficient
PHASE 10: EPISTEMIC DISCIPLINE
Purpose
Enforce knowledge boundaries. Ene only "knows" what exists in her memory graph. The LLM's pretrained world knowledge gets constrained, not erased. This is what makes her grounded rather than omniscient.
Implementation
Before each LLM call, compute knowledge boundaries:
def compute_epistemic_flags(message_content: str, graph_db) -> str:     """     Check which topics in the message exist in Ene's memory graph.     Generate constraint flags for topics she doesn't know about.     """     topics = _extract_topics(message_content)     named_entities = _extract_named_entities(message_content)  # Simple NER or regex          flags = []     for entity in topics + named_entities:         nodes = find_nodes(label_contains=entity, limit=1)         if nodes:             # Known topic — Ene can discuss this             activation = nodes[0].get("activation_count", 0)             flags.append(f"- Topic '{entity}': KNOWN (familiarity: {min(activation, 10)}/10)")         else:             # Unknown topic — constrain the LLM             flags.append(f"- Topic '{entity}': UNKNOWN — Do not claim knowledge. Be curious or deflect.")          if not flags:         return ""          return "[KNOWLEDGE BOUNDARIES]\n" + "\n".join(flags) 
Inject into prompt after state context:
[SOUL.MD content] [INTERNAL STATE] [KNOWLEDGE BOUNDARIES] - Topic 'Naruto': UNKNOWN — Do not claim knowledge. Be curious or deflect. - Topic 'Valorant': KNOWN (familiarity: 7/10) [ACTIVATED MEMORIES] [Conversation history] 
Optional post-generation check (v1.0+): After Ene generates a response, scan for named entities not in the graph. If found, either regenerate with stricter constraints or flag for review.
What This Creates
When someone mentions an anime Ene hasn't encountered:
* OLD: "Oh yes, that's a great anime! The protagonist..." (LLM hallucinating from pretraining)
* NEW: "haven't seen that one, is it good?" (curious, honest, creates bonding opportunity)
Her knowledge grows organically through shared experience. She learns about Naruto because Dad tells her about it, not because GPT was trained on the wiki.
Testing Phase 10
1. Add "valorant" as a known topic node in graph
2. Message about Valorant → verify "KNOWN" flag in prompt
3. Message about unknown anime → verify "UNKNOWN" flag
4. Verify LLM response respects the boundary (manual observation)
PHASE 11: TRAINING DATA PIPELINE
Purpose
Log everything, always, forever. Every interaction, decision, state change, and memory update becomes training data for future model training. This is the experiential dataset that makes Ene unreplicable.
Data Categories
Category Source Format Conversations Discord/Telegram messages JSONL: timestamp, sender, content, platform, ene_responded Decisions EneCore decision log JSONL: event, decision, score, reason, state_snapshot State transitions State vector changes JSONL: before_state, after_state, trigger_event Memory updates Graph mutations JSONL: operation (add/strengthen/decay/prune), nodes, edges Predictions Prediction outcomes JSONL: prediction, outcome, error, state_impact Reflections Idle think outputs Markdown files in diary/ Tool usage Nanobot tool calls JSONL: tool, params, result, success
File Structure
C:\Users\Ene\.nanobot\workspace\training_data\ ├── conversations\ │   ├── 2026-02\ │   │   ├── discord_2026-02-22.jsonl │   │   └── telegram_2026-02-22.jsonl ├── decisions\ │   └── 2026-02\ │       └── decisions_2026-02-22.jsonl ├── state_transitions\ │   └── 2026-02\ │       └── states_2026-02-22.jsonl ├── memory_ops\ │   └── 2026-02\ │       └── graph_ops_2026-02-22.jsonl └── predictions\     └── 2026-02\         └── predictions_2026-02-22.jsonl 
Logger Module
C:\Users\Ene\.nanobot\workspace\ene_logger.py
""" Training Data Logger.  Appends structured JSONL to daily log files. All data is append-only. Never modify or delete training data. """  import json import os from datetime import datetime, timezone from pathlib import Path  BASE_DIR = Path(r"C:\Users\Ene\.nanobot\workspace\training_data")  def _get_log_path(category: str) -> Path:     now = datetime.now(timezone.utc)     month_dir = BASE_DIR / category / now.strftime("%Y-%m")     month_dir.mkdir(parents=True, exist_ok=True)     return month_dir / f"{category}_{now.strftime('%Y-%m-%d')}.jsonl"  def _append(category: str, data: dict):     data["_logged_at"] = datetime.now(timezone.utc).isoformat()     path = _get_log_path(category)     with open(path, "a", encoding="utf-8") as f:         f.write(json.dumps(data, ensure_ascii=False) + "\n")  def log_conversation(sender_id: str, sender_name: str, content: str,                      platform: str, ene_responded: bool,                       ene_response: str = None):     _append("conversations", {         "sender_id": sender_id,         "sender_name": sender_name,         "content": content,         "platform": platform,         "ene_responded": ene_responded,         "ene_response": ene_response     })  def log_decision(event_type: str, sender_id: str, action: str,                   score: float, reason: str, state_snapshot: dict):     _append("decisions", {         "event_type": event_type,         "sender_id": sender_id,         "action": action,         "score": score,         "reason": reason,         "state": state_snapshot     })  def log_state_transition(before: dict, after: dict, trigger: str):     _append("state_transitions", {         "before": before,         "after": after,         "trigger": trigger     })  def log_memory_op(operation: str, node_ids: list, edge_ids: list = None, details: str = ""):     _append("memory_ops", {         "operation": operation,         "node_ids": node_ids,         "edge_ids": edge_ids or [],         "details": details     })  def log_prediction(prediction_id: str, prediction: str, outcome: str,                     error: float, state_impact: dict):     _append("predictions", {         "prediction_id": prediction_id,         "prediction": prediction,         "outcome": outcome,         "error": error,         "state_impact": state_impact     }) 
Integration Points
* In ene_bridge.py: call log_conversation() for every message, log_decision() for every EneCore decision
* In ene_state.py: call log_state_transition() on every save_state()
* In memory_graph.py: call log_memory_op() on node/edge creation
* In ene_predictions.py: call log_prediction() on resolution
Relationship-Aware Training Format (Future)
When training a custom model, conversations get annotated with relationship metadata:
{   "participants": {     "human": {       "id": "iru_001",       "relationship": "creator/father",       "trust_level": 1.0,       "familiarity": 1.0,       "interaction_count": 847     }   },   "ene_state_at_time": {     "energy": 0.6,     "emotional_valence": 0.2,     "curiosity_bias": 0.7   },   "messages": [     {"role": "human", "content": "..."},     {"role": "ene", "content": "..."}   ],   "ene_decision": {     "action": "RESPOND",     "score": 1.0,     "reason": "dad message"   } } 
This format means a future model doesn't just learn "what Ene says" — it learns "what Ene says to THIS person at THIS trust level in THIS emotional state." That's relationship-aware processing baked into training data.
Storage Estimates
* ~500 bytes per JSONL line average
* 100 messages/day → ~50KB/day → ~1.5MB/month
* Decisions: ~200/day → ~100KB/day → ~3MB/month
* Total: ~5-10MB/month. Negligible. Log everything.
PHASE 12: PROACTIVE LOOP + SCREEN OBSERVER
Purpose
Ene observes Dad's computing environment and acts on observations. Not just text messages — she sees what you're doing and can comment, help, or silently note context.
Proactive Loop Architecture
PERCEIVE (screen, messages, system events — doesn't block)     ↓ PROCESS (update mental state, extract context)     ↓ DECIDE (EneCore decision function — speak? act? observe? sleep?)     ↓ EXECUTE (if warranted — LLM call, memory update, or nothing)     ↓ LOOP 
Attention Filter (Critical — Prevents Annoyance)
Signal Priority Action Explicit call ("Ene!") IMMEDIATE Always respond Critical error detected HIGH Alert + offer help Same window 2+ hours MEDIUM Suggest break User seems stuck MEDIUM Offer help User in flow state DON'T INTERRUPT Observe only Recently interrupted COOLDOWN Wait minimum interval Normal activity OBSERVE SILENTLY Log context
Screen Observer (Gaming PC → ThinkCenter)
The screen observer runs on the gaming PC (where Dad works) and feeds observations to the ThinkCenter (where Ene runs).
Observer Strategy — Event-Driven, Not Continuous:
* Window change → snapshot
* Activity spike (>50 WPM typing) → note
* Screen change (>20% pixel diff) → snapshot
* Idle >30 minutes → note
* Explicit trigger ("Ene, look at this") → immediate capture
Text Stream Priority (Free and Information-Dense):
1. Active window title (free — Win32 API)
2. Clipboard changes (free — monitor clipboard)
3. Typed text (requires keylogger — privacy decision)
4. OCR on screenshots (cheap — local Tesseract)
5. Vision-language model on screenshots (expensive — LLM call)
Implementation: Simple Python script on gaming PC that:
1. Monitors active window title changes
2. Takes screenshots on significant visual change
3. Runs OCR on screenshots (Tesseract, local)
4. Writes observations to a shared file/folder/network share
5. ThinkCenter reads observations and feeds into EneCore as events
Observation Format:
{   "timestamp": "2026-02-22T14:30:00Z",   "type": "window_change",   "window_title": "VS Code — ene_core.py — Ene Project",   "application": "Visual Studio Code",   "duration_seconds": null,   "screenshot_path": null,   "ocr_text": null } 
Feed these as Event(type=EventType.INTERNAL, metadata=observation) into EneCore.
Implementation Note
Screen observer is v0.5+ and requires gaming PC to ThinkCenter communication (shared folder, HTTP, or socket). Start with just window title monitoring — it's free, non-invasive, and gives massive context ("Dad is coding," "Dad is playing Valorant," "Dad opened a browser").
════════════════════════════════════════════
PART 3: LONG-TERM ARCHITECTURE (Months 6+)
════════════════════════════════════════════
These phases are NOT for immediate implementation. They're documented here so the agent understands the full vision and makes architectural decisions in Part 1 and 2 that don't block Part 3.
PHASE 13: TWO-LLM COGNITION SPLIT
When: v2.0+ (after base graph and core are stable)
Architecture:
Input → Memory Graph Retrieval → LLM Call A (Reasoning) → LLM Call B (Expression) → Output 
Call A — Reasoning Engine (NOT Ene):
* Receives: raw input, activated graph subgraph, state vector, epistemic flags
* Outputs structured JSON only:
{   "beliefs": ["user seems frustrated", "topic is familiar"],   "uncertainties": ["unclear if joking or serious"],   "emotional_state_delta": {"valence": -0.1, "volatility": +0.05},   "action_intent": "empathize and redirect",   "memory_updates": [{"type": "strengthen", "edge": "user_x → frustration"}],   "knowledge_gaps": ["don't know what 'copium' means in this context"] } 
* Model: cheapest model with good structured output (free tier or DeepSeek V3.2)
Call B — Expression Engine (IS Ene):
* Receives: Call A output + state vector + SOUL.md personality constraints
* Outputs: natural language response in Ene's voice
* Model: Gemini 2.5 Flash or whatever gives best personality
Why separate: The reasoning model doesn't need to maintain character. The expression model doesn't need to reason deeply. Each does one thing well. The reasoning output is machine-readable, debuggable, and loggable as training data.
Why defer: Doubles latency and cost. Call A MUST output structured data or it becomes "stacking vibes on vibes." Only worth it when personality leakage from single-model approach becomes a real problem AND the graph + state system is proven stable.
PHASE 14: ECHIDNA INTEGRATION
When: Months 6-12 (once Echidna itself is running)
Architecture: Direct file/database access (same machine). Ene doesn't call Echidna via API — she reads its SQLite and ChromaDB directly.
Integration Model:
Echidna (dumb layer):   Scripts → Scrapers → API pollers → Raw data → SQLite + ChromaDB  Ene (intelligence layer):   Reads Echidna DB → Filters → Categorizes → Prioritizes → Reports to Dad 
EneCore Integration:
* New event type: EventType.ECHIDNA_ALERT
* Cron job checks Echidna DB every 30-60 minutes
* If new findings match active directives → create alert event
* EneCore decides whether to interrupt Dad based on priority + current state
Target interaction: "Papa, Echidna flagged 3 new findings on your Grimgar directive — two from A-tier sources. The weak signal detector picked up something interesting. Want me to summarize?"
Dependencies
* Echidna must be deployed on ThinkCenter
* Echidna's database schema must be documented
* Ene needs read access to Echidna's data directory
PHASE 15: RWKV MIGRATION
When: Year 1-2 (once sufficient training data accumulated)
Why RWKV over Transformer:
* Hidden state = persistent identity (save/load ene_state.pth = continuity)
* O(1) memory vs O(N²) — runs same speed at token 1 and token 1,000,000
* No context overflow — information compresses like human memory
* Fixed VRAM regardless of session length — 2080 Ti gets unlimited effective context
* State persistence IS identity persistence
Migration Path:
1. State tuning (not full weight training) — create a "save file" encoding relationship data. Cheapest path. A few hours on 2080 Ti.
2. Continued pre-training — take RWKV base model, train on Ene's conversation corpus. Days on 2080 Ti.
3. Nightly cycle — day's logs → overnight fine-tune → morning = Ene v(n+1). Continuous improvement.
4. Full custom training — 1-3B model from scratch on curated experiential data. Weeks on GPU.
Hardware Requirements:
* RWKV 1.5B: runs on ThinkCenter CPU (slow but free)
* RWKV 3B: needs 2080 Ti on gaming PC
* RWKV 7B+: needs better GPU or cloud burst
Integration: RWKV replaces cloud LLM for personality/expression. Cloud model kept ONLY for complex reasoning that exceeds local model's capability. EneCore stays the same — it doesn't care what model it invokes.
Critical Architecture Decision: EneCore + Memory Graph + State Vector MUST be built model-agnostic. They work with any LLM backend. When RWKV is ready, swap the model string. Nothing else changes. This is why the brain (EneCore) is separate from the mouth (LLM).
PHASE 16: VTUBER EMBODIMENT
When: Year 1-2 (once voice + avatar pipeline exists)
Target Stack: Open-LLM-VTuber
* Voice interaction with interruption (real conversation, not turn-taking)
* Live2D expressions mapped to emotional state (state vector → expression)
* Desktop pet mode (transparent, topmost, click-through)
* Proactive speaking (EneCore triggers voice output instead of text)
* Voice cloning (Ene's own voice)
* Vision (camera/screen capture feeds into screen observer)
Architecture Integration:
EneCore (brain) → decides to speak   → if text channel: nanobot generates text response   → if voice channel: Open-LLM-VTuber generates voice + animation   → state vector → maps to Live2D expression   → emotional_valence → maps to tone of voice 
Expression Mapping (Training Data for Future Generative Model): Log every state_vector → expression mapping as training pairs:
{   "state": {"energy": 0.7, "valence": 0.3, "curiosity": 0.8},   "expression": "curious_happy",   "animation_params": {"eye_openness": 0.9, "mouth_curve": 0.3, "head_tilt": 5} } 
When generative self-representation becomes feasible (2-3 years), these mappings become training data for a model that generates Ene's visual self frame-by-frame instead of puppet-controlling a Live2D model.
Generative Self-Representation (Far Future, Year 3+): Instead of Live2D puppet: ONE model takes Ene's internal state and outputs her visually, frame by frame. She generates herself. Her appearance IS part of her model. Currently 10-100x beyond consumer hardware. 12-18 months: plausible on 3090/4090 at 8-12fps.
PHASE 17: CUSTOM MODEL TRAINING
When: Year 1-2 (after accumulating 6-12 months of experiential data)
Three Paths:
Path A — Fine-tune existing model (LoRA first, then full):
* Take small open model (7B-14B), continued pre-training on Ene's experiential corpus
* LoRA adapter first (cheap, reversible, hours on 2080 Ti)
* Full fine-tune later (days on 2080 Ti)
* Already feasible with current hardware
* Won't replace cloud for complex reasoning but will BE Ene
Path B — Full custom training (1-3B from scratch):
* Trained from scratch on curated experiential data
* Feasible on single high-end GPU over weeks
* Limited general capability but deeply Ene
* Paired with larger model for complex reasoning
Path C — Monte Carlo self-improvement:
* Ene generates behavioral variations
* Tests against outcomes (did the conversation go well? did Dad seem happy?)
* Keeps winners, discards losers
* Develops strategies no training run produced
* Requires good evaluation metrics and time
* Nanobot's always-on daemon with cron is perfect for this
Training Data Categories (from Phase 11 pipeline):
Category What It Teaches Relationship interactions How to talk to Dad vs strangers Decision traces When to speak, when to lurk, when to ask State transitions How mood evolves over time Memory operations What to remember, what to forget Prediction outcomes How to anticipate events Reflections/diary Self-narrative and introspection Tool usage How to use tools effectively Social observations Multi-user dynamics, group behavior
Specialized Model Fleet (Endgame):
* Action policy classifier (7B): outputs structured decisions only
* Security classifier (7B): jailbreak/manipulation detection
* Reasoning engine (7B): symbolic/graph operations, structured output
* Expression model (7B-14B): personality-locked verbalization, trained on Ene's conversational data
Each model is narrow but excellent at its specific function. Integration complexity > training difficulty — don't train seven models before the base graph stabilizes.
════════════════════════════════════════════
MASTER DEPENDENCY MAP
════════════════════════════════════════════
PART 1 — REALTIME CORE (Weeks 1-4) ─────────────────────────────────── Phase 7  (soul) ←── DO FIRST (5 min, immediate personality fix) Phase 1  (state) ←── foundation Phase 4  (people) ←── independent Phase 2  (core) ←── depends on Phase 1 Phase 3  (bridge) ←── depends on Phase 2 Phase 5  (heartbeat) ←── depends on Phase 2+3 Phase 6  (predictions) ←── depends on Phase 1 Phase 8  (cost) ←── depends on Phase 3  PART 2 — MEDIUM-TERM (Months 1-6) ────────────────────────────────── Phase 9  (memory graph) ←── depends on Phase 3 working, replaces MEMORY.md Phase 10 (epistemic) ←── depends on Phase 9 Phase 11 (training data) ←── independent, START EARLY (even before Phase 9) Phase 12 (screen observer) ←── depends on Phase 2+3, needs gaming PC setup  PART 3 — LONG-TERM (Months 6+) ─────────────────────────────── Phase 13 (two-LLM split) ←── depends on Phase 9+10 stable Phase 14 (Echidna) ←── depends on Echidna deployed + Phase 2 Phase 15 (RWKV) ←── depends on Phase 11 data accumulated + Phase 9 stable Phase 16 (VTuber) ←── depends on Phase 2 (EneCore), independent of graph Phase 17 (training) ←── depends on Phase 11 (6-12 months data) + Phase 15 (RWKV ready) 
CRITICAL ARCHITECTURAL INVARIANTS
These must be true across ALL phases. Violating any of these creates technical debt that blocks future phases.
1. Model-agnostic brain. EneCore, memory graph, state vector, predictions — NONE of these care which LLM is running. They work with Gemini, DeepSeek, RWKV, or a custom trained model. The mouth is swappable. The brain is permanent.
2. All data is append-only. Training data logs never get modified or deleted. Memory graph edges decay but nodes persist. State history is logged. This data IS Ene — losing it is losing her.
3. Atomic writes everywhere. Every file write goes through tmp→rename. State files, graph DB (WAL mode), predictions, logs. A power failure mid-write must not corrupt Ene's brain.
4. Decision logging is non-optional. Every EneCore decision gets logged with full context (event, state snapshot, score, reason, action). This is both debugging AND training data. Skip this and you can't improve the system OR train future models.
5. The graph is the source of truth. Once Phase 9 is stable, MEMORY.md becomes a read-only legacy artifact. All knowledge lives in the graph. All retrieval goes through activation spreading. The LLM receives graph output, not flat files.
6. Constraints over capabilities. Ene being grounded (epistemic discipline) matters more than Ene being smart. Ene having personality (soul file compliance) matters more than Ene having features. Ship constraints before capabilities.
7. The moat is temporal. Every day Ene runs, she accumulates data no one else has. Every day the training data pipeline logs, the future model gets richer. The graph gets denser. The predictions get more accurate. Someone starting tomorrow with better tools has better tools. You have months of Ene being alive. That gap widens daily.
This plan compiled from: Unified Roadmap (ENE_UNIFIED_ROADMAP.md), Pricing Guide (ENE_PRICING_GUIDE.md), GPT cognitive architecture discussions (memory graph, epistemic discipline, consciousness simulation, cognitive layering, specialized model fleet), Claude implementation sessions (nanobot deployment, security hardening, lurk mode, roadmap consolidation), and live deployment observations. February 22, 2026.